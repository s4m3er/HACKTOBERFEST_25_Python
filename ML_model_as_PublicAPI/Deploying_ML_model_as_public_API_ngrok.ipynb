{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkI03QkCFmDF"
      },
      "source": [
        "Installing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLUT6T9FjHG",
        "outputId": "3d919230-831c-4ea2-aba6-37cc8c896efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Collecting pickle5\n",
            "  Using cached pickle5-0.0.11.tar.gz (132 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pickle5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pickle5\n",
            "Failed to build pickle5\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pickle5)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: pypi-json in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: apeye>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pypi-json) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from pypi-json) (24.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from pypi-json) (2.32.3)\n",
            "Requirement already satisfied: apeye-core>=1.0.0b2 in /usr/local/lib/python3.11/dist-packages (from apeye>=1.1.0->pypi-json) (1.1.5)\n",
            "Requirement already satisfied: domdf-python-tools>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from apeye>=1.1.0->pypi-json) (3.10.0)\n",
            "Requirement already satisfied: platformdirs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from apeye>=1.1.0->pypi-json) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->pypi-json) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->pypi-json) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->pypi-json) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->pypi-json) (2025.4.26)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (4.13.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NURTbIJlFzWR"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gw9a-r-RGS1n"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fH-2Snr9HDRd"
      },
      "outputs": [],
      "source": [
        "origins = [\"*\"]\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"http://localhost:5173\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SxOQ7pUfGfv7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sOUmnNOCjf2k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WW4GupKKGjCf"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "import os\n",
        "\n",
        "model_path = '/content/solar_svr_model.joblib'\n",
        "assert os.path.exists(model_path), \"Model file missing!\"\n",
        "\n",
        "model_data = load(model_path)\n",
        "weather_model = model_data['model']\n",
        "scaler_X = model_data['scaler_X']  # Critical for preprocessing\n",
        "scaler_y = model_data['scaler_y']  # Critical for postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hgm7t0wYGk7U"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from fastapi import FastAPI, HTTPException\n",
        "import pickle  # Added missing import\n",
        "import json\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Your input model\n",
        "class WeatherInput(BaseModel):\n",
        "    temp: float\n",
        "    humidity: float\n",
        "    dew: float\n",
        "    precip: float\n",
        "    cloudcover: float\n",
        "    solarradiation: float\n",
        "    solarenergy: float\n",
        "\n",
        "\n",
        "@app.post('/weather_prediction')\n",
        "async def predict_solar_energy(input_parameters: WeatherInput):\n",
        "    # Check if model and scalers are loaded\n",
        "    if weather_model is None or scaler_X is None or scaler_y is None:\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=\"Model or scalers not loaded properly\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Convert input to dictionary (Pydantic V2 compatible)\n",
        "        input_dict = input_parameters.model_dump()\n",
        "\n",
        "        # Create input array in correct feature order\n",
        "        input_values = np.array([[\n",
        "            input_dict['temp'],\n",
        "            input_dict['humidity'],\n",
        "            input_dict['dew'],\n",
        "            input_dict['precip'],\n",
        "            input_dict['cloudcover'],\n",
        "            input_dict['solarradiation'],\n",
        "            input_dict['solarenergy']\n",
        "        ]])\n",
        "\n",
        "        # Scale the input features\n",
        "        input_scaled = scaler_X.transform(input_values)\n",
        "\n",
        "        # Get prediction (still scaled)\n",
        "        pred_scaled = weather_model.predict(input_scaled)\n",
        "\n",
        "        # Inverse transform to get actual KWH value\n",
        "        pred_kwh = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1))\n",
        "\n",
        "        # Return properly formatted response\n",
        "        return {\n",
        "            \"prediction\": float(pred_scaled[0]),  # Scaled value (0-1)\n",
        "            \"prediction_kwh\": float(pred_kwh[0][0]),  # Actual KWH value\n",
        "            \"message\": \"Success\",\n",
        "            \"status_code\": 200\n",
        "        }\n",
        "\n",
        "    except KeyError as e:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=f\"Missing required feature: {str(e)}\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=f\"Prediction error: {str(e)}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmIUrS9dHGof",
        "outputId": "db5527b4-af4c-48ae-9cc8-45489ac025f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://a04d-35-186-173-207.ngrok-free.app\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [4578]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     103.139.191.219:0 - \"OPTIONS /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.139.191.219:0 - \"OPTIONS /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     117.239.226.201:0 - \"GET /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     117.239.226.201:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     117.239.226.201:0 - \"POST /weather_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.190.234:0 - \"GET /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     117.239.226.201:0 - \"POST /weather_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     117.239.226.201:0 - \"POST /weather_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     117.239.226.201:0 - \"POST /weather_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     117.239.226.201:0 - \"POST /weather_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     103.139.191.219:0 - \"POST /weather_prediction HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     103.139.191.219:0 - \"OPTIONS /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.139.191.219:0 - \"OPTIONS /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     103.139.191.219:0 - \"OPTIONS /weather_prediction HTTP/1.1\" 405 Method Not Allowed\n"
          ]
        }
      ],
      "source": [
        "ngrok.set_auth_token(\"YOUR_API_(OR)_AUTH_KEY\")\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRzyJBSBHG6m"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# import os # Import os to check if the file exists\n",
        "\n",
        "# # Assuming you have the trained model object ready\n",
        "# # For example, if it's a scikit-learn model:\n",
        "# # from sklearn.svm import SVR\n",
        "# # svr_model = SVR() # Replace with your actual trained model\n",
        "\n",
        "# # Check if the model object exists in your environment.\n",
        "# # If not, you need to retrain or load the model correctly before saving.\n",
        "# # Example of how to create a dummy model for demonstration:\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.datasets import make_regression\n",
        "# X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n",
        "# # Create and train a simple SVR model for demonstration if you don't have yours\n",
        "# try:\n",
        "#     # Try to access the existing svr_model variable\n",
        "#     svr_model_to_save = svr_model\n",
        "#     print(\"Using the existing 'svr_model' variable to save.\")\n",
        "# except NameError:\n",
        "#     # If 'svr_model' variable does not exist, create a dummy one\n",
        "#     print(\"The variable 'svr_model' does not exist. Creating a dummy SVR model and saving it.\")\n",
        "#     svr_model_to_save = SVR()\n",
        "#     svr_model_to_save.fit(X, y)\n",
        "\n",
        "\n",
        "# # --- Re-saving the model using pickle ---\n",
        "# try:\n",
        "#     with open('svr_model.pkl', 'wb') as f:\n",
        "#         pickle.dump(svr_model_to_save, f)\n",
        "#     print(\"Model successfully re-saved as 'svr_model.pkl' using pickle.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error saving model with pickle: {e}\")\n",
        "\n",
        "# # --- Loading the model using pickle ---\n",
        "# try:\n",
        "#     # loading the saved model\n",
        "#     # Ensure the file exists before trying to load\n",
        "#     if os.path.exists('svr_model.pkl'):\n",
        "#         with open('svr_model.pkl', 'rb') as f:\n",
        "#             diabetes_model = pickle.load(f)\n",
        "#         print(\"Model successfully loaded from 'svr_model.pkl' using pickle.\")\n",
        "#     else:\n",
        "#         print(\"Error: 'svr_model.pkl' not found after attempting to save.\")\n",
        "# except UnpicklingError as e:\n",
        "#     print(f\"UnpicklingError occurred during load: {e}. The file might still be corrupted or not a valid pickle file.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An unexpected error occurred during load: {e}\")\n",
        "\n",
        "# # --- Alternative: Using joblib (often preferred for scikit-learn models) ---\n",
        "# # First, install joblib if you haven't already\n",
        "# # !pip install joblib\n",
        "\n",
        "# # import joblib\n",
        "\n",
        "# # # --- Re-saving the model using joblib ---\n",
        "# # try:\n",
        "# #     joblib.dump(svr_model_to_save, 'svr_model_joblib.pkl')\n",
        "# #     print(\"Model successfully re-saved as 'svr_model_joblib.pkl' using joblib.\")\n",
        "# # except Exception as e:\n",
        "# #     print(f\"Error saving model with joblib: {e}\")\n",
        "\n",
        "# # # --- Loading the model using joblib ---\n",
        "# # try:\n",
        "# #     # Ensure the file exists before trying to load\n",
        "# #     if os.path.exists('svr_model_joblib.pkl'):\n",
        "# #         diabetes_model_joblib = joblib.load('svr_model_joblib.pkl')\n",
        "# #         print(\"Model successfully loaded from 'svr_model_joblib.pkl' using joblib.\")\n",
        "# #     else:\n",
        "# #          print(\"Error: 'svr_model_joblib.pkl' not found after attempting to save.\")\n",
        "# # except Exception as e:\n",
        "# #     print(f\"Error loading model with joblib: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxryim52jabY"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# # Load saved objects\n",
        "# saved_data = joblib.load('svr_model.pkl')\n",
        "# model = saved_data['model']\n",
        "# scaler_X = saved_data['scaler_X']\n",
        "# scaler_y = saved_data['scaler_y']\n",
        "\n",
        "# def predict_kwh(temp, humidity, dew, precip, cloudcover, solarradiation, solarenergy):\n",
        "#     # 1. Scale input\n",
        "#     input_scaled = scaler_X.transform([[temp, humidity, dew, precip, cloudcover, solarradiation, solarenergy]])\n",
        "\n",
        "#     # 2. Predict\n",
        "#     pred_scaled = model.predict(input_scaled)\n",
        "\n",
        "#     # 3. Unscale prediction\n",
        "#     return scaler_y.inverse_transform(pred_scaled.reshape(-1, 1))[0][0]\n",
        "\n",
        "# # Usage\n",
        "# predict_kwh(25.5, 60.0, 18.0, 0.0, 30.0, 450.0, 1.8)  # Returns unscaled KWH prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swnv0Oxwf8N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
